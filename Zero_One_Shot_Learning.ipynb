{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f06170d-de3a-43c7-b921-c7334a57a888",
   "metadata": {},
   "source": [
    "# Zero-shot and One-shot Learning using Large Language Models for De-Identification of Medical Records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40771c-69c5-408b-8c6a-3c0ec2634942",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "All medical records are now digitalized and the old records are also being converted to digital records. These medical records have sensitive personal data related to the patient and even medical professionals, which is a threat to their pirvacy. Removal or censoring of personal identifiable information embedded within the medical records is call de-identification. \n",
    "\n",
    "Dataset used - https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/ ( Have to request for permission for this data, if you want to access this dataset) \n",
    "\n",
    "Here, we use the recent Large Lanaguage Models like GPT-3.5, GPT-4, PaLM, Llama, Bard to evaluate how they perform on de-identification task.\n",
    "\n",
    "#### Model Accuracies for Zero Shot Learning\n",
    "\n",
    "|  | Brief Prompt |  Detailed Prompt | Test Sample Size |\n",
    "|----------|----------|----------|----------|\n",
    "| GPT-3.5 | 69% | 96% | 514 |\n",
    "| GPT-4 | 96% | 99% | 100 |\n",
    "| PaLM | 71% | 74% | 514 |\n",
    "| Bard | * | * | 100 |\n",
    "| Llama-7B | ** | ** | 100 |\n",
    "\n",
    "\\* Llama-7B model produced very inconsistent results. For some, medical records it returns says that it is not allowed to de-identify medical records and sometimes it produced different text from what was given as part of the prompt \n",
    "\n",
    "** Same with Bard. Bard official API is not publically available. But there is python package available and the experiment was based on it. So, bard experiment is not included in this notebook\n",
    "\n",
    "### Model Training and Accuracies for One Shot Learning\n",
    "\n",
    "Both GPT-3.5 and PaLM LLMs were training and fine tuned as per our needs. GPT-3.5 outforms GPT-4 when fined tuned with just 30 sample data files and trained for 3 epochs. There is considerable increase in PaLM model also when fine tuned\n",
    "\n",
    "|                                | Training Set Size | Validation Set Size | Approx Cost   |\n",
    "|--------------------------------|-------------------|---------------------|---------------|\n",
    "| GPT-3.5 with brief prompts     | 30                | 10                  | `$1.4`        |\n",
    "| GPT-3.5 with detailed prompts  | 30                | 10                  | `$2.3`        |\n",
    "| PaLM with brief prompts        | 50                | NA                  | Free          |\n",
    "| PaLM with detailed prompts     | 50                | NA                  | Free          |\n",
    "\n",
    "\n",
    "\n",
    "|                                | Brief Prompts | Detailed Prompts | Test Set Size   |\n",
    "|--------------------------------|-------------------|---------------------|---------------|\n",
    "| GPT-3.5      | 96%                | 98%                 | 100        |\n",
    "| PaLM         | 87%                | 93%                 | 100          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76795bc-ac9a-4ff5-b6a7-502e4124f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!pip3 install openai\n",
    "!pip3 install requests\n",
    "!pip3 install tiktoken\n",
    "!pip3 install bardapi\n",
    "!pip3 install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d60a6331-5163-4d5f-83f9-84a42e7cb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import os\n",
    "import requests\n",
    "import openai\n",
    "import shutil\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from bs4 import BeautifulSoup\n",
    "from statistics import mean\n",
    "import google.generativeai as palm\n",
    "from llama_cpp import Llama\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index.llms.base import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce799f4d-8ec5-440f-9bc3-2825f7b238f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read API keys from config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/Users/yashwanthys/Desktop/config.ini')\n",
    "openai.api_key = config['API_KEYS']['OPENAI_API_KEY']\n",
    "palm.configure(api_key = config['API_KEYS']['PALM_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9b393d-c74f-4741-9ca0-d5b233f46202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>owned_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-search-babbage-doc-001</td>\n",
       "      <td>model</td>\n",
       "      <td>1651172509</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>model</td>\n",
       "      <td>1685474247</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>curie-search-query</td>\n",
       "      <td>model</td>\n",
       "      <td>1651172509</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>model</td>\n",
       "      <td>1683758102</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text-search-babbage-query-001</td>\n",
       "      <td>model</td>\n",
       "      <td>1651172509</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id object     created         owned_by\n",
       "0    text-search-babbage-doc-001  model  1651172509       openai-dev\n",
       "1         gpt-3.5-turbo-16k-0613  model  1685474247           openai\n",
       "2             curie-search-query  model  1651172509       openai-dev\n",
       "3              gpt-3.5-turbo-16k  model  1683758102  openai-internal\n",
       "4  text-search-babbage-query-001  model  1651172509       openai-dev"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetching all avaliable models of OpenAI \n",
    "models = openai.Model.list()\n",
    "data = pd.DataFrame(models[\"data\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc345f47-dca7-4036-9b86-767a4619546f",
   "metadata": {},
   "source": [
    "### Prompt\n",
    "This the prompt or the common instruction given to all the large language models. Detailed prompt is the ideal prompt in terms of accuracy and from cost perspective. Detailed prompt is designed in such a way that it is of ideal length and proper examples are included for each instruction. Brief prompt is good in terms of cost but performs poorly in terms of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fbdc1e8-8cab-4318-b60e-24c99ecc58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_prompt = '''Task: Please anonymize the following clinical note. Replace all the Protected health information (PHI) text with the '[censored]'.'''\n",
    "\n",
    "\n",
    "detailed_prompt = '''Task: Please anonymize the following clinical note.\n",
    "\n",
    "Specific Instructions: Replace all the following Protected health information (PHI) text with the '[censored]'.\n",
    "\n",
    "1) Censor any string or substring that has name, including patients, doctors, any acronyms, initials, and medical titles\n",
    "\n",
    "2) Censor any string or substring that indicate profession with any mentions of job titles, like medical staff professional names, such as 'M.D.' and 'Dr.'.\n",
    "\n",
    "3) Censor any string or substring with location, including addresses, clinic names, hospital names, and any other possible location indicators, such as '920 River Street'.\n",
    "\n",
    "4) Censor any string or substring that indicate age, such as \"Over 80 years\" or \"Aged 70\".\n",
    "\n",
    "5) Censor any string or substring that indicate dates, including record dates, admit dates, decharge dates etc, such as '27/09/2090' or '07/06' or '2090-08-25'\n",
    "\n",
    "6) Censor any string or substring with contact information, including phone numbers, email, fax, URLs and IP Addresses'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bd9a27d-5119-4d57-9e75-33f2588d2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_single_xml(file_path: str) -> str:\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    text = root.find('TEXT').text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4017a4bd-8038-448e-be52-97074280b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_request function makes a API call to particular gpt model and fetches the result for the prompt provided\n",
    "def gpt_request(model, system_prompt, user_report, temperature):\n",
    "    Chat_Completion = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_report}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return Chat_Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a252b8e-c73f-4253-a882-224bdc25a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process xml files which have the medical records using LLM models\n",
    "def process_single_file(filename, input_folder, output_folder, model, system_prompt, temperature):\n",
    "    # Construct file paths\n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "    censored_filename = filename.replace('.xml', '_censored.txt')\n",
    "    censored_file_path = os.path.join(output_folder, censored_filename)\n",
    "\n",
    "    try:\n",
    "        # Parse the XML file and extract the text\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "        text_element = root.find('TEXT')\n",
    "        if text_element is not None and text_element.text is not None:\n",
    "            text_content = text_element.text.strip()\n",
    "        else:\n",
    "            print(f\"No text found in {filename}\")\n",
    "            return\n",
    "\n",
    "        # Make the API call\n",
    "        if model in [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-4\", \"ft:gpt-3.5-turbo-0613:personal:briefprompt-deid2:8Hr8yYi1\", \"ft:gpt-3.5-turbo-0613:personal:detailedpromptdeid:8I0NZ50z\"]:\n",
    "            gpt_reponse = gpt_request(model=model, system_prompt=system_prompt, user_report=text_content, temperature=temperature)\n",
    "            censored_text = gpt_reponse.choices[0].message.content\n",
    "        elif model == \"PaLM\":\n",
    "            palm_response = palm.chat(context=system_prompt, messages=text_content, temperature=temperature)\n",
    "            censored_text = palm_response.last\n",
    "        else:\n",
    "            raise ValueError(f\"Model {model} is not supported.\")\n",
    "\n",
    "        # Write the response to a file in the output folder\n",
    "        with open(censored_file_path, 'w') as censored_file:\n",
    "            censored_file.write(censored_text)\n",
    "\n",
    "        print(f\"Processed {filename} and saved response to {censored_file_path}\")\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing {filename}: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {filename}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802f94c3-dc15-420d-96be-fcc7b4c90bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process files in parallel for gpt models\n",
    "def process_xml_files(input_folder, output_folder, model, system_prompt, temperature):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    xml_files = [f for f in sorted(os.listdir(input_folder)) if f.endswith(\".xml\")]\n",
    "\n",
    "    # Use ThreadPoolExecutor to process files in parallel\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        # Submit tasks to the executor\n",
    "        futures = [executor.submit(process_single_file, filename, input_folder, output_folder, model, system_prompt, temperature) for filename in xml_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead0ffe3-dd5d-45c3-91d4-f849429fd459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script taken from - https://github.com/yhydhx/ChatGPT-API/blob/main/process_xml_public.py and modified\n",
    "# Uncomment print statements if detailed analysis of each report is required\n",
    "def words_in_string(word_list, a_string):\n",
    "    return set(word_list).intersection(a_string.split())\n",
    "\n",
    "# Calculates accuracy of the models\n",
    "def check_deidentification_accuracy(rewrite_directory, original_directory):\n",
    "    list_of_files_to_check = []\n",
    "    list_of_anonymized_reports = []\n",
    "\n",
    "    for filename in os.listdir(rewrite_directory):\n",
    "        f = os.path.join(rewrite_directory, filename)\n",
    "        if os.path.isfile(f):\n",
    "            target_file = os.path.basename(os.path.normpath(f))[:-13]\n",
    "            list_of_files_to_check.append(target_file)\n",
    "\n",
    "            text_file = open(f, \"r\")\n",
    "            data = text_file.read()\n",
    "            list_of_anonymized_reports.append(data)\n",
    "            text_file.close()\n",
    "\n",
    "    list_of_accuracies = []\n",
    "\n",
    "    for i in range(len(list_of_files_to_check)):\n",
    "        names = []\n",
    "        professions = []\n",
    "        locations = []\n",
    "        ages = []\n",
    "        dates = []\n",
    "        contacts = []\n",
    "        ids = []\n",
    "\n",
    "        names_count = 0\n",
    "        professions_count = 0\n",
    "        locations_count = 0\n",
    "        ages_count = 0\n",
    "        dates_count = 0\n",
    "        contacts_count = 0\n",
    "        ids_count = 0\n",
    "\n",
    "        with open(os.path.join(original_directory, list_of_files_to_check[i] + \".xml\")) as fp:\n",
    "            soup = BeautifulSoup(fp, features=\"xml\")\n",
    "\n",
    "            tags = soup.find(\"TAGS\")\n",
    "\n",
    "            for name_tag in tags.find_all('NAME'):\n",
    "                names.append(name_tag.get('text'))\n",
    "\n",
    "            for profession_tag in tags.find_all('PROFESSION'):\n",
    "                professions.append(profession_tag.get('text'))\n",
    "\n",
    "            for location_tag in tags.find_all('LOCATION'):\n",
    "                locations.append(location_tag.get('text'))\n",
    "\n",
    "            for age_tag in tags.find_all('AGE'):\n",
    "                ages.append(age_tag.get('text'))\n",
    "\n",
    "            for date_tag in tags.find_all('DATE'):\n",
    "                dates.append(date_tag.get('text'))\n",
    "\n",
    "            for contact_tag in tags.find_all('CONTACT'):\n",
    "                contacts.append(contact_tag.get('text'))\n",
    "\n",
    "            for id_tag in tags.find_all('ID'):\n",
    "                ids.append(id_tag.get('text'))\n",
    "\n",
    "            #print(\"==========================\")\n",
    "            #print(list_of_files_to_check[i])\n",
    "            a_string = list_of_anonymized_reports[i]\n",
    "\n",
    "            for word in words_in_string(names, a_string):\n",
    "                names_count += 1\n",
    "\n",
    "            for word in words_in_string(professions, a_string):\n",
    "                professions_count += 1\n",
    "\n",
    "            for word in words_in_string(locations, a_string):\n",
    "                locations_count += 1\n",
    "\n",
    "            for word in words_in_string(ages, a_string):\n",
    "                ages_count += 1\n",
    "\n",
    "            for word in words_in_string(dates, a_string):\n",
    "                dates_count += 1\n",
    "\n",
    "            for word in words_in_string(contacts, a_string):\n",
    "                contacts_count += 1\n",
    "\n",
    "            for word in words_in_string(ids, a_string):\n",
    "                ids_count += 1\n",
    "\n",
    "            total_remaining = names_count + professions_count + locations_count + ages_count + dates_count + contacts_count + ids_count\n",
    "            total_length = len(names) + len(professions) + len(locations) + len(ages) + len(dates) + len(contacts) + len(ids)\n",
    "\n",
    "            accuracy = 1 - (total_remaining / total_length)\n",
    "            list_of_accuracies.append(accuracy)\n",
    "            #print(\"Remaining number of strings and Accuracy: \", total_remaining, accuracy)\n",
    "            #print(\"==========================\\n\")\n",
    "\n",
    "    #print(len(list_of_files_to_check))\n",
    "    average_accuracy = mean(list_of_accuracies)\n",
    "    print(\"Average accuracy =\", round(average_accuracy, 3))\n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d1118-ba53-40ec-aa95-a2a237e2ad97",
   "metadata": {},
   "source": [
    "### GPT-3.5-turbo model with brief prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bef109-7100-4bf3-8495-f477154a7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gpt-3.5-turbo'\n",
    "temperature = 0.05\n",
    "test_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed'\n",
    "output_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_3.5_test_results2'\n",
    "process_xml_files(test_folder_path, output_folder_path, model, brief_prompt, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f18dd79-b841-45e5-87b1-778ec597f606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.692\n"
     ]
    }
   ],
   "source": [
    "rewrite_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_3.5_test_results2'\n",
    "original_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed'\n",
    "accuracy_detailed_prompt = check_deidentification_accuracy(rewrite_directory,original_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba6504-e660-47e1-9019-c5605a2ee454",
   "metadata": {},
   "source": [
    "### GPT-3.5-turbo with detailed prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791e63a-f001-4c13-8b17-9ba017a6be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gpt-3.5-turbo-16k'\n",
    "temperature = 0.05\n",
    "test_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed'\n",
    "output_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_3.5_test_result2'\n",
    "process_xml_files(test_folder_path, output_folder_path, model, detailed_prompt, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e01569fd-1630-4474-8bf2-5a8562fe0544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.955\n"
     ]
    }
   ],
   "source": [
    "rewrite_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_3.5_test_result2'\n",
    "original_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed'\n",
    "accuracy_detailed_prompt = check_deidentification_accuracy(rewrite_directory,original_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002377e4-6baf-4ddd-b9d0-4856841ddf8e",
   "metadata": {},
   "source": [
    "### GPT-4 with brief prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf7d5c-2461-4cd3-9aa0-5ee27ce5314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gpt-4'\n",
    "temperature = 0.05\n",
    "test_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "output_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_4_test_results2'\n",
    "process_xml_files(test_folder_path, output_folder_path, model, brief_prompt, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9b9464-d206-470d-9917-b90a77b4aa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.956\n"
     ]
    }
   ],
   "source": [
    "rewrite_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_4_test_results2'\n",
    "original_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "accuracy_detailed_prompt = check_deidentification_accuracy(rewrite_directory,original_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff53df-49fd-49af-acd1-f83e0e9992e4",
   "metadata": {},
   "source": [
    "### GPT-4 with detailed prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fbfb62-1357-4911-9327-c04fc320d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gpt-4'\n",
    "temperature = 0.05\n",
    "test_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "output_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_4_test_result2'\n",
    "process_xml_files(test_folder_path, output_folder_path, model, detailed_prompt, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc3f2f3b-2de6-4fc7-9a86-1a331a5c1bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.985\n"
     ]
    }
   ],
   "source": [
    "rewrite_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_4_test_result2'\n",
    "original_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "accuracy_detailed_prompt = check_deidentification_accuracy(rewrite_directory,original_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7789bd-75a6-4e28-ae37-e26772e37f78",
   "metadata": {},
   "source": [
    "### PaLM with brief prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ebc8a7-6109-4916-a0b9-4e3f66d10f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"PaLM\"\n",
    "temperature = 0.1\n",
    "test_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "output_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_palm_test_results2'\n",
    "process_xml_files(test_folder_path, output_folder_path, model, brief_prompt, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcf6ec57-8d7c-432a-a7ed-640ba18fba77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.71\n"
     ]
    }
   ],
   "source": [
    "rewrite_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_palm_test_results2'\n",
    "original_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "accuracy_detailed_prompt = check_deidentification_accuracy(rewrite_directory,original_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc42952d-a4c2-4ae2-a349-e58d4bbdd09b",
   "metadata": {},
   "source": [
    "### PaLM with detailed prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be542bf1-5981-4ca7-9417-345465811619",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'PaLM'\n",
    "temperature = 0.1\n",
    "test_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "output_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_palm_test_result2'\n",
    "process_xml_files(test_folder_path, output_folder_path, model, detailed_prompt, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68695c49-6291-4318-90f6-d9c4f46608ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.739\n"
     ]
    }
   ],
   "source": [
    "rewrite_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_palm_test_result2'\n",
    "original_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "accuracy_detailed_prompt = check_deidentification_accuracy(rewrite_directory,original_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c745cb-35ec-4127-b518-58bf7aa9432b",
   "metadata": {},
   "source": [
    "### Llama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b6cb18-1136-42f8-8b8c-24cd65760d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the locally downloaded Llama model\n",
    "llama = LlamaCPP(model_path=\"/Users/yashwanthys/PersonalProjects/llama2/llama.cpp/models/7B/ggml-model-q4_0.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1dd08e9-9fd5-4919-9544-14e7e788af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time = 52729.91 ms\n",
      "llama_print_timings:      sample time =   172.33 ms /   256 runs   (    0.67 ms per token,  1485.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 52396.62 ms /   256 runs   (  204.67 ms per token,     4.89 tokens per second)\n",
      "llama_print_timings:       total time = 53464.00 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', additional_kwargs={}), raw={'id': 'cmpl-dd6bbe46-13e6-45b7-b4d6-e11630561501', 'object': 'text_completion', 'created': 1699121346, 'model': '/Users/yashwanthys/PersonalProjects/llama2/llama.cpp/models/7B/ggml-model-q4_0.bin', 'choices': [{'text': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 1558, 'completion_tokens': 256, 'total_tokens': 1814}}, delta=None, additional_kwargs={})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with a sindle sample xml file whoch has a medical record\n",
    "# Run this cell multiple times and check the results. Sometimes it does not de identify info and \n",
    "# tells that it is not allowed do this particular task or it performs very poorly\n",
    "medical_report = parse_single_xml('/Users/yashwanthys/Downloads/testing-PHI-Gold-fixed/110-03.xml')\n",
    "message1 = ChatMessage(role='system',content=detailed_prompt)\n",
    "message2 = ChatMessage(role=\"user\",content=medical_report)\n",
    "llama.chat([message1,message2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b63ac-780b-486d-82fb-a97fe5ab3674",
   "metadata": {},
   "source": [
    "# Fine Tuned Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c841330e-1082-424a-abab-b09e12e77c5f",
   "metadata": {},
   "source": [
    "### GPT-3.5 model fine tuned with brief prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37f9701f-e30c-45e7-b0c0-dce7d9ac5089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 110-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/110-01_censored.txt\n",
      "Processed 110-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/110-02_censored.txt\n",
      "Processed 110-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/110-03_censored.txt\n",
      "Processed 110-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/110-04_censored.txt\n",
      "Processed 111-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/111-01_censored.txt\n",
      "Processed 111-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/111-02_censored.txt\n",
      "Processed 111-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/111-03_censored.txt\n",
      "Processed 111-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/111-04_censored.txt\n",
      "Processed 112-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/112-01_censored.txt\n",
      "Processed 112-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/112-02_censored.txt\n",
      "Processed 112-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/112-03_censored.txt\n",
      "Processed 112-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/112-04_censored.txt\n",
      "Processed 112-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/112-05_censored.txt\n",
      "Processed 113-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/113-01_censored.txt\n",
      "Processed 113-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/113-02_censored.txt\n",
      "Processed 113-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/113-03_censored.txt\n",
      "Processed 113-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/113-04_censored.txt\n",
      "Processed 113-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/113-05_censored.txt\n",
      "Processed 114-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/114-01_censored.txt\n",
      "Processed 114-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/114-02_censored.txt\n",
      "Processed 114-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/114-03_censored.txt\n",
      "Processed 114-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/114-04_censored.txt\n",
      "Processed 115-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/115-01_censored.txt\n",
      "Processed 115-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/115-02_censored.txt\n",
      "Processed 115-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/115-03_censored.txt\n",
      "Processed 115-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/115-04_censored.txt\n",
      "Processed 116-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/116-01_censored.txt\n",
      "Processed 116-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/116-02_censored.txt\n",
      "Processed 116-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/116-03_censored.txt\n",
      "Processed 116-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/116-04_censored.txt\n",
      "Processed 116-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/116-05_censored.txt\n",
      "Processed 117-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/117-01_censored.txt\n",
      "Processed 117-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/117-02_censored.txt\n",
      "Processed 118-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/118-01_censored.txt\n",
      "Processed 118-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/118-02_censored.txt\n",
      "Processed 118-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/118-03_censored.txt\n",
      "Processed 118-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/118-04_censored.txt\n",
      "Processed 118-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/118-05_censored.txt\n",
      "Processed 119-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/119-01_censored.txt\n",
      "Processed 119-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/119-02_censored.txt\n",
      "Processed 119-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/119-03_censored.txt\n",
      "Processed 119-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/119-04_censored.txt\n",
      "Processed 119-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/119-05_censored.txt\n",
      "Processed 130-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/130-01_censored.txt\n",
      "Processed 130-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/130-02_censored.txt\n",
      "Processed 130-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/130-03_censored.txt\n",
      "Processed 130-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/130-04_censored.txt\n",
      "Processed 130-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/130-05_censored.txt\n",
      "Processed 131-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/131-01_censored.txt\n",
      "Processed 131-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/131-02_censored.txt\n",
      "Processed 131-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/131-03_censored.txt\n",
      "Processed 131-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/131-04_censored.txt\n",
      "Processed 131-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/131-05_censored.txt\n",
      "Processed 132-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/132-01_censored.txt\n",
      "Processed 132-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/132-02_censored.txt\n",
      "Processed 132-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/132-03_censored.txt\n",
      "Processed 132-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/132-04_censored.txt\n",
      "Processed 132-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/132-05_censored.txt\n",
      "Processed 134-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/134-01_censored.txt\n",
      "Processed 134-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/134-02_censored.txt\n",
      "Processed 134-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/134-03_censored.txt\n",
      "Processed 134-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/134-04_censored.txt\n",
      "Processed 134-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/134-05_censored.txt\n",
      "Processed 135-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/135-01_censored.txt\n",
      "Processed 135-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/135-02_censored.txt\n",
      "Processed 135-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/135-03_censored.txt\n",
      "Processed 135-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results/135-04_censored.txt\n"
     ]
    }
   ],
   "source": [
    "model = 'ft:gpt-3.5-turbo-0613:personal:briefprompt-deid2:8Hr8yYi1'\n",
    "temperature = 0.05\n",
    "test_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "output_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results'\n",
    "process_xml_files(test_folder_path, output_folder_path, model, brief_prompt, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35ad4d74-7142-4eb5-9b56-146ec9eedac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.955\n"
     ]
    }
   ],
   "source": [
    "rewrite_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/breif_gpt_fune_tine_results'\n",
    "original_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "accuracy_detailed_prompt = check_deidentification_accuracy(rewrite_directory,original_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f299ccb-2bdc-4a68-957f-11e5d1162cab",
   "metadata": {},
   "source": [
    "### Fine tuned GPT-3.5 model with detailed prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffa15826-bb0f-42fc-b6ca-ab953b09b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 110-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/110-01_censored.txt\n",
      "Processed 110-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/110-02_censored.txt\n",
      "Processed 110-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/110-03_censored.txt\n",
      "Processed 110-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/110-04_censored.txt\n",
      "Processed 111-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/111-01_censored.txt\n",
      "Processed 111-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/111-02_censored.txt\n",
      "Processed 111-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/111-03_censored.txt\n",
      "Processed 111-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/111-04_censored.txt\n",
      "Processed 112-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/112-01_censored.txt\n",
      "Processed 112-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/112-02_censored.txt\n",
      "Processed 112-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/112-03_censored.txt\n",
      "Processed 112-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/112-04_censored.txt\n",
      "Processed 112-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/112-05_censored.txt\n",
      "Processed 113-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/113-01_censored.txt\n",
      "Processed 113-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/113-02_censored.txt\n",
      "Processed 113-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/113-03_censored.txt\n",
      "Processed 113-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/113-04_censored.txt\n",
      "Processed 113-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/113-05_censored.txt\n",
      "Processed 114-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/114-01_censored.txt\n",
      "Processed 114-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/114-02_censored.txt\n",
      "Processed 114-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/114-03_censored.txt\n",
      "Processed 114-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/114-04_censored.txt\n",
      "Processed 115-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/115-01_censored.txt\n",
      "Processed 115-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/115-02_censored.txt\n",
      "Processed 115-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/115-03_censored.txt\n",
      "Processed 115-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/115-04_censored.txt\n",
      "Processed 116-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/116-01_censored.txt\n",
      "Processed 116-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/116-02_censored.txt\n",
      "Processed 116-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/116-03_censored.txt\n",
      "Processed 116-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/116-04_censored.txt\n",
      "Processed 116-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/116-05_censored.txt\n",
      "Processed 117-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/117-01_censored.txt\n",
      "Processed 117-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/117-02_censored.txt\n",
      "Processed 118-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/118-01_censored.txt\n",
      "Processed 118-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/118-02_censored.txt\n",
      "Processed 118-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/118-03_censored.txt\n",
      "Processed 118-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/118-04_censored.txt\n",
      "Processed 118-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/118-05_censored.txt\n",
      "Processed 119-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/119-01_censored.txt\n",
      "Processed 119-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/119-02_censored.txt\n",
      "Processed 119-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/119-03_censored.txt\n",
      "Processed 119-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/119-04_censored.txt\n",
      "Processed 119-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/119-05_censored.txt\n",
      "Processed 130-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/130-01_censored.txt\n",
      "Processed 130-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/130-02_censored.txt\n",
      "Processed 130-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/130-03_censored.txt\n",
      "Processed 130-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/130-04_censored.txt\n",
      "Processed 130-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/130-05_censored.txt\n",
      "Processed 131-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/131-01_censored.txt\n",
      "Processed 131-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/131-02_censored.txt\n",
      "Processed 131-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/131-03_censored.txt\n",
      "Processed 131-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/131-04_censored.txt\n",
      "Processed 131-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/131-05_censored.txt\n",
      "Processed 132-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/132-01_censored.txt\n",
      "Processed 132-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/132-02_censored.txt\n",
      "Processed 132-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/132-03_censored.txt\n",
      "Processed 132-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/132-04_censored.txt\n",
      "Processed 132-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/132-05_censored.txt\n",
      "Processed 134-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/134-01_censored.txt\n",
      "Processed 134-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/134-02_censored.txt\n",
      "Processed 134-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/134-03_censored.txt\n",
      "Processed 134-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/134-04_censored.txt\n",
      "Processed 134-05.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/134-05_censored.txt\n",
      "Processed 135-01.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/135-01_censored.txt\n",
      "Processed 135-02.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/135-02_censored.txt\n",
      "Processed 135-03.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/135-03_censored.txt\n",
      "Processed 135-04.xml and saved response to /Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results/135-04_censored.txt\n"
     ]
    }
   ],
   "source": [
    "model = 'ft:gpt-3.5-turbo-0613:personal:detailedpromptdeid:8I0NZ50z'\n",
    "temperature = 0.05\n",
    "test_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "output_folder_path = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results'\n",
    "process_xml_files(test_folder_path, output_folder_path, model, brief_prompt, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b35a04c-321c-49c5-901f-4d735a7930e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.977\n"
     ]
    }
   ],
   "source": [
    "rewrite_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/detailed_gpt_fune_tine_results'\n",
    "original_directory = '/Users/yashwanthys/PersonalProjects/ML_Proj/De-Identification/testing-PHI-Gold-fixed-short'\n",
    "accuracy_detailed_prompt = check_deidentification_accuracy(rewrite_directory,original_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c1b6c-1b92-41a4-83bd-71e7005e0411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
